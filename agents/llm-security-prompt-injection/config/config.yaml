# Configuration for Llm-Security-Prompt-Injection
agent:
  name: "Llm-Security-Prompt-Injection"
  description: "This project investigates the security of large language models by performing binary classification of a set of input prompts to discoverâ€¦"
  github_url: "https://github.com/sinanw/llm-security-prompt-injection](https://github.com/sinanw/llm-security-prompt-injection"
  
# Add your configuration here
