---
name: Llm-Adapters
description: Code for our EMNLP 2023 Paper - "LLM-Adapters - An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models"
---

# Llm-Adapters

Code for our EMNLP 2023 Paper - "LLM-Adapters - An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models"

## How to Use

Visit the official resource: [https://github.com/AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters)

### Installation

If this is a GitHub repository, you can typically clone and install it:

```bash
git clone https://github.com/AGI-Edgerunners/LLM-Adapters
cd LLM-Adapters
# Follow the repository's README for specific installation instructions
```

### Getting Started

Please refer to the official documentation and repository for detailed setup and usage instructions.


## Resources

- Official Link: [https://github.com/AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters)
