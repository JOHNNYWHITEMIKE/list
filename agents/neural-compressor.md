---
name: Neural-Compressor
description: SOTA low-bit LLM quantization (INT8/FP8/INT4/FP4/NF4) & sparsity; leading model compression techniques on TensorFlow, PyTorch, and ONNX R…
---

# Neural-Compressor

SOTA low-bit LLM quantization (INT8/FP8/INT4/FP4/NF4) & sparsity; leading model compression techniques on TensorFlow, PyTorch, and ONNX R…

## How to Use

Visit the official resource: [https://github.com/intel/neural-compressor](https://github.com/intel/neural-compressor)

### Installation

If this is a GitHub repository, you can typically clone and install it:

```bash
git clone https://github.com/intel/neural-compressor
cd neural-compressor
# Follow the repository's README for specific installation instructions
```

### Getting Started

Please refer to the official documentation and repository for detailed setup and usage instructions.


## Resources

- Official Link: [https://github.com/intel/neural-compressor](https://github.com/intel/neural-compressor)
